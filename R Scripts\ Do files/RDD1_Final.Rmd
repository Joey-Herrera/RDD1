---
title: "RDD1"
author: "Joey Herrera"
date: "2/14/2021"
output: pdf_document
---
#Regression Discontinuity Design Replication

Note: Questions 1 through 5 were completed using R. I had difficulty completely replicating question 6 through 8 using R, so I used STATA instead. In those code chunks I added the function EVAL=FALSE so the STATA code block would not run. Then, I posted the required output below its associated code chunk.

##Question 2: Summary of Hansen's RDD paper

Hansen wrote this paper to add to the literature on recidivism by focusing on the recidivism rates and people driving under the influence. Hansen's research project attempts to answer the question, "What effects do harsher punishments and sanctions have on recidivism rates for people driving under the influence?" This study's data are blood alcohol content (BAC) test results from the state of Washington from 1999-2007. Choosing 1999-2007 as a time frame allows Hansen to define recidivism as a repeat offender charged with another DUI within a four-year window of their last DUI. Thus, the overarching time frame considered is 1995-2011. This dataset was cleaned to not include individuals under the drinking age since they would bias the recidivism rates and the results of this study.  Hansen used a regression discontinuity design to estimate the effects of harsher punishments on recidivism rates for people driving under the influence. Using BAC tests as the running variable, Hansen chose two different thresholds at 0.08 and 0.15. 0.08 represents the level of BAC that qualifies for the issuing of a DUI. 0.15 represents the BAC threshold where an individual can receive an aggravated DUI. These two thresholds separate the observations into three distinct sets where punishments increase as BAC increases and observations go from one group of observations to another. Observations are put into groups of first-time offenders, repeat offenders, and a set of all DUI offenders. From his empirical model, Hansen concludes that first-time DUI offenders with a BAC between 0.08 and 0.15 have a higher recidivism rate than that of any other group.

```{r setup, include=TRUE, message=FALSE, output=FALSE}
library(learnr)
library(haven) #For data upload
library(tidyverse)
library(stargazer)
library(estimatr)
library(rdd)
library(rdrobust)
library(rddensity)
library(ggplot2)
library(jtools)
library(knitr)
library(kableExtra)

#Load in DUI data
Hansen <- read_dta("/Users/josephherrera/desktop/Causal Inference/hansen_dwi.dta")

```

Question 3: Create a dummy variable when BAC is greater than or equal to 0.08.
```{r echo=FALSE, results='hide', warning=FALSE}
Hansen_dummy = Hansen %>%
  mutate(dui = ifelse(bac1 >= 0.08,1 ,0))

head(Hansen_dummy)
```
The coode above creates a dummy variable using 0.08 as the cutoff threshold. When the first blood alcohol test is greater than or equal to 0.08, then the individual is considered to be driving under the influence (dui). For these observations the dummy variable takes on the value of 1. If not, the driver will not recieve a dui. Thus, the dummyvariable for that observation takes on the value 0.

Question 4: Look for evidence of manipulation
```{r echo=TRUE, warning=FALSE}
cli::cli_text("Search for Manipulation Evidence")
ggplot(data = Hansen_dummy) +
  geom_histogram(aes(bac1, color = factor(dui)),alpha = 0.5, bins = 50) +
  geom_vline(xintercept = 0.08, colour = "black", linetype = 1) +
  geom_vline(xintercept = 0.15, color = "black", linetype = 1) +
  labs(x = "BAC 1 (X)", y = "Frequency (Y)")
```
If people where capable of manipulating their blood alcohol levels, I would test for manipulation by looking for non-random heaping by looking at a histogram. I would also run a regression discontinuity with bac1 as the running variable and a y-variable of interest to see if there is a change in density along around the 0.08 and 0.15 thresholds. After recreating figure 1, I see no evidence of non-random heaping on the running variable. The data has a contiuous distribution of blood alcohol content levels. The evidence I found recreating Figure 1 from Hansen's paper agrees with his analysis testing for the same form of manipulation.

Question 5: Check the Covariate Balance
```{r echo=TRUE}

malecov <-RDestimate(male ~ bac1 | white + aged + acc + dui + dui*bac1 ,data = Hansen_dummy, cutpoint = 0.08, kernel="rectangular", bw = 0.05)

agedcov <- RDestimate(aged ~ bac1 | white + male + acc + dui + dui*bac1 ,data = Hansen_dummy, cutpoint = 0.08, kernel="rectangular", bw = 0.05)

whitecov <- RDestimate(white ~ bac1 | male + aged + acc + dui + dui*bac1 ,data = Hansen_dummy, cutpoint = 0.08, kernel="rectangular", bw = 0.05)

acccov <- RDestimate( acc ~ bac1 | white + aged + male + dui + dui*bac1 ,data = Hansen_dummy, cutpoint = 0.08, kernel="rectangular", bw = 0.05)
  
CovBal = data.frame(
  Estimates = c("Coeff", "SE", "Z", "P-value", "Confidence Interval"),
  m = c(malecov$est[1], malecov$se[1], malecov$z[1], malecov$p[1], malecov$ci[1]),
  w = c(whitecov$est[1], whitecov$se[1], whitecov$z[1], malecov$p[1], malecov$ci[1]),
  ag = c(agedcov$est[1], agedcov$se[1], malecov$z[1], malecov$p[1], malecov$ci[1]),
  scc = c(acccov$est[1], acccov$se[1], acccov$z[1], malecov$p[1], malecov$ci[1])
)

CovBal %>%
  kable(colnames = c("Characteristic", "Male", "White", "Age", "Accident"),
        digits = 3,
        caption = "Covariate Balance Panel A"
  ) %>%
  kable_classic(full_width = F, html_font = "Cambria")
```

The covariates are balanced. There is no sign of treatment effects assigned to individuals on personal characteristics. As a result, Also,there is no bias that comes from unrandom assigned treatment grouping,

Question 6: Recreate Figure 2 Panels A-D
```{r echo=TRUE, eval=FALSE}
#Question 6 - Replication of Figure 2 Panel A-D 
#Disjointed panel for characteristics for quadratic models

cmogram male bac1, cut(0.08) scatter line(0.08) qfitci
cmogram white bac1, cut(0.08) scatter line(0.08) qfitci
cmogram aged bac1, cut(0.08) scatter line(0.08) qfitci
cmogram acc bac1, cut(0.08) scatter line(0.08) qfitci

rdplot male bac1, c(0.08) p(2)
rdplot white bac1, c(0.08) p(2)
rdplot aged bac1, c(0.08) p(2)
rdplot acc bac1, c(0.08) p(2)

#Disjointed panel for linear model
cmogram male bac1, cut(0.08) scatter line(0.08) lfitci
cmogram white bac1, cut(0.08) scatter line(0.08) lfitci
cmogram aged bac1, cut(0.08) scatter line(0.08) lfitci
cmogram acc bac1, cut(0.08) scatter line(0.08) lfitci

rdplot male bac1, c(0.08) p(1)
rdplot white bac1, c(0.08) p(1)
rdplot aged bac1, c(0.08) p(1)
rdplot acc bac1, c(0.08) p(1)


```



Question 7: Replicate Table 3 Column 1 for Panels A and B
```{r echo=FALSE}
#Estimate equation 1 with recidivism as the outcome Panel A
Column1A <- RDestimate(recidivism ~ bac1 | dui ,data = Hansen_dummy, cutpoint = 0.08, kernel="rectangular", bw = c(0.03,0.13), se.type = "HC")
Column1A

Column2A <- RDestimate(recidivism ~ bac1 |  dui + dui*bac1 ,data = Hansen_dummy, cutpoint = 0.08, kernel="rectangular", bw = c(0.03,0.13), se.type = "HC")
Column2A

Column3A <- RDestimate(recidivism ~ bac1 | dui + dui*bac1 + (dui)*(bac1^2) ,data = Hansen_dummy, cutpoint = 0.08, bw = c(0.03, 0.13), kernel="rectangular", se.type = "HC")
Column3A

#Estimate equation 1 with recidivism as the outcome Panel B
Column1B <- RDestimate(recidivism ~ bac1 | dui + dui*bac1 ,data = Hansen_dummy, cutpoint = 0.08, kernel="rectangular", bw = c(0.055,0.105), se.type = "HC")
Column1B

Column2B <- RDestimate(recidivism ~ bac1 |  dui + dui*bac1 ,data = Hansen_dummy, cutpoint = 0.08, kernel="rectangular", bw = c(0.055,0.105), se.type = "HC")
Column2B

Column3B <- RDestimate(recidivism ~ bac1 | dui + dui*bac1 + (dui)*(bac1^2) ,data = Hansen_dummy, cutpoint = 0.08, bw = c(0.055, 0.105), kernel="rectangular", se.type = "HC")
Column3B
```

Question 8: Replicate Figure 3 Panel A with a linear and quadratic fits
```{r eval=FALSE warning=FALSE}
cmogram recidivism bac1, cut(0.08) scatter line(0.08) qfitci
cmogram recidivism bac1, cut(0.08) scatter line(0.08) lfitci

rdplot recidivism bac1 if bac1<0.15, c(0.08) p(2)
rdplot recidivism bac1 if bac1<0.15, c(0.08) p(1)
```








